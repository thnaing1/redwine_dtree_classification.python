{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b638726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "#import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66bd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\An-94\\\\desktop\\\\ucr\\\\CS235\\\\project') #use os library to find the correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e004088",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv(\"winequality-red-undelimited-preprocessed_2.csv\", \n",
    "                           usecols = ['fixed acidity','volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'above_average'])\n",
    "\n",
    "#import the dataset as pandas dataframe; exclude the wine quality column since we are designating a seperate column of binary\n",
    "#values 1 and 0 where 1 represents the wines whos quality is equal to or above 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dec269e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>above_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  above_average  \n",
       "0      9.4              0  \n",
       "1      9.8              0  \n",
       "2      9.8              0  \n",
       "3      9.8              0  \n",
       "4      9.4              0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f084e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = red_wine.loc[:,red_wine.columns != \"above_average\"]\n",
    "y = red_wine[\"above_average\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835db45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4fdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4aa4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = cross_val_score(clf, x_train, y_train, cv = 10, scoring = 'recall')\n",
    "np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec26488",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sem(recall) #recall sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d97a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, x_train, y_train, cv = 10, scoring = 'precision')\n",
    "precision = cross_val_score(clf, x_train, y_train, cv = 10, scoring = 'precision')\n",
    "np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b07de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sem(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70749192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf219172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07672db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbd24075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data, feature, boundary): #create a function the partition's data based on where it falls on the boundary condition\n",
    "    true_rows = data[data[feature] >= boundary ]\n",
    "    false_rows = data[data[feature] < boundary ]\n",
    "    \n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce104e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data, target): #the gini impurity for calculating the impurity of parent, and child nodes\n",
    "\n",
    "    counts = data[target].value_counts()\n",
    "    impurity = 1\n",
    "    \n",
    "    for c in counts:\n",
    "        prob_of_label = c/float(len(data))\n",
    "        impurity -= prob_of_label**2\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94d914b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty, target): #the function to calculate information gain\n",
    "\n",
    "    p = float(len(left))/(len(left)+len(right))\n",
    "    split_uncertainty = p*gini(left, target) + (1-p)*gini(right, target)\n",
    "    ig = current_uncertainty - split_uncertainty\n",
    "    \n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34dd1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data, target):#pick the best feature and boundary combination that produces the highest information gain \n",
    "    #initialize the best gain, feature, and boundary variables\n",
    "\n",
    "    best_gain = 0\n",
    "    best_feature = None\n",
    "    best_boundary = None\n",
    "    current_uncertainty = gini(data, target)\n",
    "    features = data.columns.drop(target)\n",
    "\n",
    "    for f in features: #interate over features\n",
    "        if best_feature == None:\n",
    "            best_feature = f\n",
    "            \n",
    "        boundaries = list(set(data[f]))\n",
    "\n",
    "        for b in boundaries: #interate over boundaries\n",
    "            if best_boundary == None:\n",
    "                best_boundary = b\n",
    "                \n",
    "            tr, fr = partition(data, f, b) #output the true rows and false rows at feature and boundary combination\n",
    "            \n",
    "            if (len(tr) == 0) or (len(fr) == 0): #if there are no true rows or false rows continue\n",
    "                continue\n",
    "\n",
    "            gain = info_gain(tr, fr, current_uncertainty, target) #fnd the information gain at the current impurity level\n",
    "\n",
    "            if gain >= best_gain: #if the current information gain is greater than the best gain then make that the new best gain\n",
    "                #(along with its feature and boundary)\n",
    "                best_gain, best_feature, best_boundary = gain, f, b\n",
    "\n",
    "    return best_gain, best_feature, best_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a1dd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_node(data, target, split_level, min_leaf, max_depth):\n",
    "    #create leaf nodes or decision nodes based on whether there was information gain\n",
    "    gain, feature, boundary = best_split(data, target)\n",
    "    node = {\n",
    "            'info_gain': gain, \n",
    "            'size': len(data), \n",
    "            'feature': feature, \n",
    "            'boundary': boundary\n",
    "           }\n",
    "    # create a node variable with keys info_gain, size, feature, and boundary\n",
    "    if (gain == 0) or (len(data) <= min_leaf) or (split_level > max_depth):\n",
    "        node['node_type'] = 'leaf' #if all conditions(no information gain, length less than min for leaf, and less than max depth)\n",
    "        # are met then create a node type called leaf\n",
    "        prediction = {} #create a dictionary called prediction\n",
    "        counts = data[target].value_counts() #get the counts of the classes\n",
    "        prediction = 0\n",
    "        prediction_chance = 0\n",
    "        for i in counts.index: #for rows in the counts index which consists of two classes\n",
    "            prediction_chance_i = counts[i]/float(len(data)) #find the general probability of the class at that index\n",
    "            if prediction_chance_i > prediction_chance: #if the general prob is greater than the current prob \n",
    "                prediction_chance = prediction_chance_i #assign the new prob to prediction chance\n",
    "                prediction = i #and make row equal to the prediction\n",
    "        node['prediction'] = prediction #after that assign the prediction row class to column prediction\n",
    "        node['prediction_chance'] = prediction_chance #and assign the new probability to the prediction chance column \n",
    "        \n",
    "    elif gain > 0:\n",
    "        node['node_type'] = 'branch' #if the information gain is greater than zero then create a node type called a branch\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5be8cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(pred, target='above_average'):\n",
    "    \n",
    "    correct_preds = pred[pred[target]==pred['predictions']] #true positive or true negative\n",
    "    correct = len(correct_preds)  # # of correct predictions\n",
    "    correct_pos_preds = correct_preds[correct_preds[target]== 1] #true positives\n",
    "    correct_positive = len(correct_pos_preds) # # of true positives\n",
    "    positive_actual = len(pred[pred[target]== 1]) #counts where real value is positive\n",
    "    positive_pred = len(pred[pred['predictions']== 1]) #counts where predicted value is positive\n",
    "    total = len(pred) #total number of predictions\n",
    "    acc = correct/total #percent of predictions that were correct\n",
    "    precision = correct_positive/positive_pred  #percentage of how often a classifier is right about the prediction\n",
    "    recall = correct_positive/positive_actual #percentage of how often a classifier successfully predict the real value\n",
    "    f1 = 2*precision*recall/(precision+recall) #harmonic mean of precision and recall\n",
    "    print('accuracy:',round(acc, 4),', precision:',round(precision, 4),', recall:',round(recall, 4),', f1:',round(f1, 4))\n",
    "    \n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e4ba7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03431894532028967, 'alcohol', 11.6)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_split(red_wine, 'above_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "723b4ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info_gain': 0.03431894532028967,\n",
       " 'size': 1599,\n",
       " 'feature': 'alcohol',\n",
       " 'boundary': 11.6,\n",
       " 'node_type': 'branch'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_node(red_wine, 'above_average', 0, 5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73986fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree(data = {}, decision_tree = {}, \n",
    "          split_level = 0, max_depth = 7, min_leaf = 5, \n",
    "          target = 'above_average'):\n",
    "    \n",
    "    if split_level == 0: #if the depth is at the root node than continue\n",
    "        root = make_node(data, target, split_level, min_leaf, max_depth) #create a node and set it to the root variable\n",
    "        root['node_type'] = 'root' #create a column in root variable called 'node type' and assign string 'root' to it\n",
    "        decision_tree[split_level] = [(data, root)] #the decision tree is a dictionary where every level consists of data and \n",
    "        #node; the data is the partitioned data for each node\n",
    "        \n",
    "    decision_tree[split_level + 1] = [] #add 1 to the split level after assignment of data and node to the root\n",
    "    keep_splitting = 0 \n",
    "    \n",
    "    \n",
    "    for d, n in decision_tree[split_level]: #d is the interator for the data and n is the interator for the nodes\n",
    "        \n",
    "        if (n['node_type'] != 'leaf'): #if the node is not a leaf it is a decision node\n",
    "            \n",
    "            gain, feature, boundary = best_split(d, target) #assign the best gain, feature and boundary at best split\n",
    "            tr, fr = partition(d, feature, boundary) #assign true rows(rows greater than or equal to that particular boundary) \n",
    "            #and false rows(rows less than boundary) at that split\n",
    "\n",
    "            right_branch = make_node(tr, target, split_level + 1, min_leaf, max_depth) #create the right branch of the tree with\n",
    "            #true rows and add one to split level\n",
    "            n['right_child_feature'] = right_branch['feature'] #for the node create a column right child feature and assign\n",
    "            # the feature variable for the left branches\n",
    "            n['right_child_boundary'] = right_branch['boundary'] #for the node create a column right child boundary and assign\n",
    "            # the boundary condition for the right branches\n",
    "            decision_tree[split_level + 1].append((tr, right_branch)) #append to the decision tree the true rows and the left\n",
    "            #branch and add one to the split level or depth\n",
    "            if (right_branch['node_type'] == 'branch'): #if the node is a left branch keep splitting\n",
    "                keep_splitting = 1\n",
    "\n",
    "            left_branch = make_node(fr, target, split_level + 1, min_leaf, max_depth)  #create the left branch of the tree with\n",
    "            #false rows and add one to split level\n",
    "            n['left_child_feature'] = left_branch['feature'] #for the node create a column right child feature and assign\n",
    "            # the feature variable for the right branches\n",
    "            n['left_child_boundary'] = left_branch['boundary'] #for the node create a column right child boundary and assign\n",
    "            # the boundary condition for the right branches\n",
    "            decision_tree[split_level + 1].append((fr, left_branch)) #append to the decision tree the true rows and the right\n",
    "            #branch and add one to the split level\n",
    "            if (left_branch['node_type'] == 'branch'):  #if the node type is a right branch keep splitting\n",
    "                keep_splitting = 1\n",
    "    \n",
    "    split_level += 1 #after the left branches and right branches are created move to the next depth level\n",
    "    #print('tree level', split_level, 'complete')\n",
    "    \n",
    "    if (keep_splitting == 1): #a recursive function that output the results of the decision tree at each split level\n",
    "        decision_tree, split_level = dtree(decision_tree = decision_tree, split_level = split_level)\n",
    "        \n",
    "    return decision_tree, split_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "286a8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, sl = dtree(data=train_df.copy(), target='above_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "edb423ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dtree(red_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43c0a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_predict(data, tree, target = 'quality_class'):\n",
    "\n",
    "    predictions = {}\n",
    "            \n",
    "    for i in range(len(data)): #iterate over the length of the data\n",
    "        \n",
    "        x = data.iloc[i] #assign the data at each i row to x\n",
    "        \n",
    "        for s in range(len(tree)):  #interate over the split levels of the tree dictionary\n",
    "            \n",
    "            if (s == 0): #if the level is at the root node\n",
    "                node = tree[s][0][1] # the first index represent the whole tree, the second represent the # of branches of the tree\n",
    "                #, and the last represents a single node at the split level in a branch\n",
    "                current_feature = node['feature'] #set the current feature and boundary\n",
    "                current_boundary = node['boundary']\n",
    "                \n",
    "            for n in range(len(tree[s])):  #for node in each length split levels\n",
    "                \n",
    "                node = tree[s][n][1]\n",
    "                \n",
    "                if ((node['feature'] == current_feature) and (node['boundary'] == current_boundary)):\n",
    "                    \n",
    "                    if (node['node_type']!='leaf'):   #if the node is not a leaf \n",
    "                        \n",
    "                        if (x[current_feature] >= current_boundary): #if the row in the current feature is greater than \n",
    "                            # or euqal to the boundary, append the features and boundaries from the right child feature and boundary columns\n",
    "                            next_feature = node['right_child_feature']\n",
    "                            next_boundary = node['right_child_boundary']\n",
    "\n",
    "                        elif (x[current_feature] < current_boundary): #if the row in the current feature is less than the boundary,\n",
    "                            #append the features and boundaries from the left child feature and boundary columns\n",
    "                            next_feature = node['left_child_feature']\n",
    "                            next_boundary = node['left_child_boundary']\n",
    "                            \n",
    "                    if (node['node_type']=='leaf'):\n",
    "                        prediction = node['prediction']  #if the node type is a leaf make a prediction\n",
    "        \n",
    "            current_feature = next_feature #new feature and boundary of the previous depth becomes the current feature and boundary\n",
    "            # of the current depth\n",
    "            current_boundary = next_boundary\n",
    "        \n",
    "        predictions[i] = prediction\n",
    "        \n",
    "    data['predictions'] = pd.Series(predictions) #generate a series of predictions and append to the predictions column in the \n",
    "    #dataframe\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a181ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpreds = dtree_predict(test_df.copy(), dt, target = 'above_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56bef34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "skf = StratifiedKFold(n_splits=10) #function for stratified 10 fold\n",
    "skf.get_n_splits(x.copy(), y.copy()) # returns the number of splitting iterations in the cross-validator\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ac94fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "skf_df = {} \n",
    "\n",
    "for train_index, test_index in skf.split(x, y): #split into k folds cross validation\n",
    "    \n",
    "    train_df = pd.concat([x.iloc[train_index], y.iloc[train_index]], axis=1).reset_index(drop=True)\n",
    "    test_df = pd.concat([x.iloc[test_index], y.iloc[test_index]], axis=1).reset_index(drop=True)\n",
    "    skf_df[fold] = [train_df, test_df]\n",
    "    fold+=1\n",
    "\n",
    "#skf_df[fold #][0=train, 1=test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3d8179b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8812 , precision: 0.625 , recall: 0.2381 , f1: 0.3448\n",
      "accuracy: 0.8438 , precision: 0.3 , recall: 0.1429 , f1: 0.1935\n",
      "accuracy: 0.8375 , precision: 0.4286 , recall: 0.5455 , f1: 0.48\n",
      "accuracy: 0.8438 , precision: 0.4286 , recall: 0.4091 , f1: 0.4186\n",
      "accuracy: 0.925 , precision: 0.8125 , recall: 0.5909 , f1: 0.6842\n",
      "accuracy: 0.8125 , precision: 0.1667 , recall: 0.0909 , f1: 0.1176\n",
      "accuracy: 0.8187 , precision: 0.3704 , recall: 0.4545 , f1: 0.4082\n",
      "accuracy: 0.8313 , precision: 0.3913 , recall: 0.4091 , f1: 0.4\n",
      "accuracy: 0.4562 , precision: 0.0988 , recall: 0.3636 , f1: 0.1553\n",
      "accuracy: 0.8491 , precision: 0.2 , recall: 0.0476 , f1: 0.0769\n"
     ]
    }
   ],
   "source": [
    "dt_cv_results_minority = [] #initilize the lists the will be result of the cross validation\n",
    "\n",
    "for fold in skf_df: #iterate over folds in the dictionary skf_df in which the indexes of the x and y cols and train and testsets are stored\n",
    "    kf_train_df = skf_df[fold][0] #iterated over the selected train dataframes and assign to a variable\n",
    "    kf_test_df = skf_df[fold][1] #iterated over the selected test dataframes and assign to a variable\n",
    "    \n",
    "    dt, sl = dtree(data=kf_train_df, target='above_average') #put the training dataset into the tree function\n",
    "    tpred = dtree_predict(kf_test_df, dt, target = 'above_average') #take the prediction results and testing data labels and \n",
    "    #put them in a list \n",
    "\n",
    "    fold_results_minority = [get_metrics(pred=tpred, target='above_average')] #figure out the performance \n",
    "    #given the predicted and test values\n",
    "    dt_cv_results_minority.append(fold_results_minority) #append each fold results into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eca72c84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall        f1\n",
      "0  0.881250   0.625000  0.238095  0.344828\n",
      "1  0.843750   0.300000  0.142857  0.193548\n",
      "2  0.837500   0.428571  0.545455  0.480000\n",
      "3  0.843750   0.428571  0.409091  0.418605\n",
      "4  0.925000   0.812500  0.590909  0.684211\n",
      "5  0.812500   0.166667  0.090909  0.117647\n",
      "6  0.818750   0.370370  0.454545  0.408163\n",
      "7  0.831250   0.391304  0.409091  0.400000\n",
      "8  0.456250   0.098765  0.363636  0.155340\n",
      "9  0.849057   0.200000  0.047619  0.076923\n",
      "accuracy     0.809906\n",
      "precision    0.382175\n",
      "recall       0.329221\n",
      "f1           0.327926\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#process the output to a more usable and appealing form\n",
    "\n",
    "dt_cv_array = np.asarray(dt_cv_results_minority)\n",
    "dt_cv_array = np.mean(dt_cv_array, axis = 1)\n",
    "dt_cv_df = pd.DataFrame(dt_cv_array)\n",
    "dt_cv_df\n",
    "\n",
    "per_report_df = dt_cv_df.rename(columns={ 0 : \"accuracy\",  1 : \"precision\",  2 : \"recall\", 3 : \"f1\"})\n",
    "per_report_mean  = per_report_df.mean(axis = 0) #calculate the mean of the k folds for the performance scores \n",
    "print(per_report_df)\n",
    "print(per_report_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a56ef39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04062494, 0.06793598, 0.06000132, 0.0601174 ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.sem(per_report_df) #standard error of the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d312f900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.456250</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.155340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.881250   0.625000  0.238095  0.344828\n",
       "1  0.843750   0.300000  0.142857  0.193548\n",
       "2  0.837500   0.428571  0.545455  0.480000\n",
       "3  0.843750   0.428571  0.409091  0.418605\n",
       "4  0.925000   0.812500  0.590909  0.684211\n",
       "5  0.812500   0.166667  0.090909  0.117647\n",
       "6  0.818750   0.370370  0.454545  0.408163\n",
       "7  0.831250   0.391304  0.409091  0.400000\n",
       "8  0.456250   0.098765  0.363636  0.155340\n",
       "9  0.849057   0.200000  0.047619  0.076923"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_report_df #results of k folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ba4dde10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.809906\n",
       "precision    0.382175\n",
       "recall       0.329221\n",
       "f1           0.327926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_report_mean #mean of the performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b149434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f235716e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.128467\n",
       "precision    0.214832\n",
       "recall       0.189741\n",
       "f1           0.190108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_report_stdev = per_report_df.std(axis = 0) #standard deviation of the performance\n",
    "per_report_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676bf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f998555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.87 accuracy for the off the shelf + or - 0.018\n",
    "#.81 accuracy for the custom + or - 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f52ae188",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,   4],\n",
       "       [ 20,   1]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(tpred['above_average'], tpred['predictions']) #confusion matrix for comparing the test data with predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
